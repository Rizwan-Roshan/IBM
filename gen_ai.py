# -*- coding: utf-8 -*-
"""GEN_AI

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15cvpkGhUuJnjDP-W51DI4EMwbEuP-6Sc
"""

from transformers import GPT2LMHeadModel, GPT2Tokenizer

def generate_text(prompt, num_sequences=1, max_length=100, temperature=0.7):
    # Load pre-trained GPT-2 model and tokenizer
    model_name = 'gpt2'
    tokenizer = GPT2Tokenizer.from_pretrained(model_name)
    model = GPT2LMHeadModel.from_pretrained(model_name)

    # Tokenize input text
    input_ids = tokenizer.encode(prompt, return_tensors='pt')

    # Generate text based on input prompt
    output = model.generate(input_ids,
                            max_length=max_length,
                            num_return_sequences=num_sequences,
                            temperature=temperature,
                            top_k=50,
                            top_p=0.95,
                            repetition_penalty=1.0,
                            do_sample=True,
                            pad_token_id=tokenizer.eos_token_id)

    # Decode generated output
    generated_text = [tokenizer.decode(seq, skip_special_tokens=True) for seq in output]

    return generated_text

def main():
    while True:
        # Prompt user for input
        prompt = input("Enter your prompt (or 'q' to quit): ")

        # Check if user wants to quit
        if prompt.lower() == 'q':
            print("Exiting...")
            break

        # Generate text based on user prompt
        generated_text = generate_text(prompt, num_sequences=3, max_length=100)

        # Display generated text
        print("\nGenerated Text:")
        for i, text in enumerate(generated_text, 1):
            print(f"Sequence {i}: {text}\n")

if __name__ == "__main__":
    main()